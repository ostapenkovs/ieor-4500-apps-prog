{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IEOR 4500. Project 5. Pairs trading\n",
    "\n",
    "In this project we address the basic elements of the pairs-trading strategy.\n",
    "\n",
    "## Notation:\n",
    "$p_i^t$ denotes the (closing) price of asset $i$ at time $t$.\n",
    "\n",
    "The basic premise is as follows. Suppose that we consider a pair $(i,j)$ of assets. When we invest $S_k$ on this pair, we do the following:\n",
    "\n",
    "- We take the position $S_k$ in asset $i$.\n",
    "- We take the position $-S_k$ in asset $j$.\n",
    "\n",
    "The worth of this position is judged as follows:\n",
    "\n",
    "- The number of shares in asset $i$ equals $k/p_i^t$.\n",
    "- The value of the position in asset $i$, at time $t+1$, equals $kp_i^{t+1}/p_i^t$.\n",
    "- The value of the position in asset $j$, at time $t+1$, equals $-kp_j^{t+1}/p_j^t$.\n",
    "\n",
    "Hence, if we close the pair position at time $t+1$, the value we accrue (gain or loss) equals\n",
    "$$kp_i^{t+1}/p_i^t - kp_j^{t+1}/p_j^t.$$\n",
    "\n",
    "Conceptually, you may have thought, throughout, that $k > 0$, i.e., we are longing $i$ and shorting $j$. However, make sure you understand that the formula is correct if $k < 0$, i.e., we short $i$ and long $j$.\n",
    "\n",
    "- Denote\n",
    "$$\\Delta_i^t = p_i^{t+1}/p_i^t - p_j^{t+1}/p_j^t,$$\n",
    "and\n",
    "$$\\bar{\\Delta}_{ij} = \\frac{1}{T} \\sum_{t=0}^{T-1} \\Delta_i^t.$$\n",
    "\n",
    "The optimization problem we want to solve is:\n",
    "\n",
    "Minimize\n",
    "$$-\\sum_{i<j} x_{ij}\\Delta_{ij} + \\theta \\left( \\frac{1}{T-1} \\sum_{t=0}^{T-1} (\\Delta_i^t - \\bar{\\Delta}_{ij})^2 \\right)$$\n",
    "(1a)\n",
    "\n",
    "Subject to\n",
    "$$-1 \\leq x_{ij} \\leq 1,$$\n",
    "for all pairs $i < j$.\n",
    "(1b)\n",
    "\n",
    "Here, $\\theta \\geq 0$ is a risk-tolerance parameter. Your code should work for values of $\\theta$ ranging from very small to large, e.g., $0 \\leq \\theta \\leq 10^6$.\n",
    "\n",
    "1. Implement a first-order method, using projected gradients, for this problem. Yes, you can also attempt to handle it using a solver, but I want to see the first-order implementation.\n",
    "\n",
    "2. You should test it using the daily data that I have uploaded; Wilshire 5000 and Russell 1000. Using the first data set you should be able to get at least 3000 names with more than 1000 valid data values that are date-aligned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in data\n",
    "data_folder = './data'\n",
    "index_name = 'closeRussell1000'\n",
    "\n",
    "delta_fname = f'{data_folder}/{index_name}_delta.pkl'\n",
    "with open(delta_fname, 'rb') as f: delta = pickle.load(f)\n",
    "n, p = delta.shape\n",
    "\n",
    "delta_bar_fname = f'{data_folder}/{index_name}_delta_bar.pkl'\n",
    "with open(delta_bar_fname, 'rb') as f: delta_bar = pickle.load(f)\n",
    "\n",
    "pair_names_fname = f'{data_folder}/{index_name}_pair_names.pkl'\n",
    "with open(pair_names_fname, 'rb') as f: pair_names = pickle.load(f)\n",
    "\n",
    "# computing centered delta array. takes too long to do here, need to do faster in process_data.ipynb\n",
    "delta_centered = delta - delta_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x: np.ndarray, theta: float, pi: float) -> np.ndarray:\n",
    "    '''Function which we intend to minimize. Vectorized.'''\n",
    "    t = len(x)\n",
    "    return -np.dot(delta_bar, x) + theta/t * np.linalg.norm(delta_centered @ x, pi)**pi\n",
    "\n",
    "def g(x: np.ndarray, theta: float, pi: float) -> np.ndarray:\n",
    "    '''Gradient of function f. Vectorized.'''\n",
    "    t = len(x)\n",
    "    delta_centered_at_x = delta_centered @ x\n",
    "    return -delta_bar + (theta / t * pi) * ((delta_centered_at_x**(pi-1)).T @ delta_centered)\n",
    "\n",
    "def gradient_descent() -> tuple:\n",
    "    '''Gradient descent function. Using gradient normalization, momentum, clipping, and batches. Vectorized.'''\n",
    "    # for iter in iters:\n",
    "    #   for batch in batches:\n",
    "    #       eval grad => norm grad => step with momentum => clip it => check convergence\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    x_0 = np.random.uniform(-1, 1, p),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
